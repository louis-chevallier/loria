{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Séminaire IMT Grand-Est\n",
    "\n",
    "# Introduction à l'apprentissage automatique - TP6 exercice 1\n",
    "\n",
    "### SVM sur données synthétiques\n",
    "\n",
    "<br> \n",
    "\n",
    "Prenez connaissance de la [documentation scikit-learn sur les SVM](http://scikit-learn.org/stable/modules/svm.html).\n",
    "\n",
    "On utilisera la [classe SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n",
    "\n",
    "Notez la valeur par défaut de l'hyperparamètre $C$, et les fonctions noyau disponibles (ainsi que leurs paramètres).\n",
    "\n",
    "<br>\n",
    "\n",
    "Dans les questions suivantes, vous séparerez les bases de données\n",
    "entre bases d'apprentissage (80% de la base initiale) et base de test (20%) en utilisant `model_selection.train_test_split`, et vous calculerez un score de\n",
    "classification sur la base de test.\n",
    "\n",
    "<br>\n",
    "\n",
    "On commence par charger les bibliothèques utiles et définir une fonction de visualisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, model_selection, preprocessing, model_selection, svm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_classif_result_SVM(X,y,clf,title):\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])\n",
    "    cmap_bold = ListedColormap(['#FF0000', '#00FF00'])    \n",
    "    cmap2 = ListedColormap(['#FF8888', '#FFAAAA', '#AAFFAA', '#88FF88'])  \n",
    "    \n",
    "    h=0.01 # step size in the mesh\n",
    "    \n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Zdf = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Zdfbin = (np.abs(Zdf)<=1)   # 0 if inside margin,  1 if outside \n",
    "    Color=np.zeros(Z.shape)  # colors for each region \n",
    "    for i in range(len(Z)):\n",
    "        if (Z[i]):\n",
    "            if Zdfbin[i]: Color[i]=2\n",
    "            else: Color[i]=3\n",
    "        else:\n",
    "            if Zdfbin[i]: Color[i]=1 \n",
    "            else: Color[i]=0\n",
    "                \n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    Color = Color.reshape(xx.shape)    \n",
    "    plt.figure(figsize=[8,8])\n",
    "    plt.pcolormesh(xx, yy, Color, cmap=cmap2)\n",
    "    \n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n",
    "                edgecolor='k', s=20)\n",
    "    \n",
    "    # Plot the support vectors:\n",
    "    plt.scatter(X[clf.support_, 0], X[clf.support_, 1], c=y[clf.support_], cmap=cmap_bold,edgecolor='k',s=80, marker='*')    \n",
    "    \n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(title);\n",
    "    plt.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commencez par un jeu de données de 1000 points dans deux classes linéairement séparables, obtenu avec `make_blobs` (comme fait dans un des TP précédents). \n",
    "\n",
    "Entraînez une SVM à noyau linéaire, et visualisez les vecteurs supports à l'aide de la fonction `plot_classif_result_SVM`.\n",
    "\n",
    "Affichez également le score de classification sur la base test, ainsi que le nombre de vecteurs supports pour chaque classe.\n",
    "\n",
    "Même question avec deux classes non séparables (augmentez la valeur de `cluster_std` dans `make_blobs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# génération dataset\n",
    "# faire plusieurs exécutions: les deux classes ne sont pas toujours linéairement séparables\n",
    "X_dataset, y_dataset = datasets.make_blobs(n_features=2, centers=2, cluster_std=1.0, n_samples=1000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_dataset,y_dataset,test_size=.2)\n",
    "\n",
    "# affichage dataset train+test\n",
    "plt.figure()\n",
    "plt.scatter(X_dataset[:, 0], X_dataset[:, 1], marker='o', c=y_dataset,\n",
    "            s=25, edgecolor='k')\n",
    "plt.title('dataset')\n",
    "plt.axis(\"equal\")\n",
    "\n",
    "# votre code ici: entraînant SVM et visualisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Reprenez le jeu de données synthétique `make_moons`:\n",
    " ```python\n",
    "X_dataset, y_dataset = datasets.make_moons(noise=0.2, n_samples=1000)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_dataset,y_dataset,test_size=.2)\n",
    "```\n",
    " Visualisez\n",
    "  le résultat de la SVM linéaire, et vérifiez que diminuer la valeur de l'hyperparamètre $C$ augmente le nombre de vecteurs supports (et change la surface de séparation). Vous essaierez les valeurs de $C$ suivantes: 0.01, 1, 100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# génération dataset\n",
    "X_dataset, y_dataset = datasets.make_moons(noise=0.2, n_samples=1000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_dataset,y_dataset,test_size=.2)\n",
    "\n",
    "# affichage dataset train+test\n",
    "plt.figure()\n",
    "plt.scatter(X_dataset[:, 0], X_dataset[:, 1], marker='o', c=y_dataset,\n",
    "            s=25, edgecolor='k')\n",
    "plt.title('dataset')\n",
    "\n",
    "# Votre code ici:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observez le résultat de la classification avec un noyau\n",
    "  gaussien (RBF), et l'évolution selon différentes valeurs du\n",
    "  paramètre `gamma` (on gardera $C=1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# votre code ici:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le noyau RBF et la valeur par défaut de $\\gamma$, discutez l'influence de $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# votre code ici:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Pour trouver une valeur optimale aux hyperparamètres $\\gamma$ et $C$ par validation croisée, on dispose de la fonction [GridSearchCV](scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) rencontrée au TP précédent.\n",
    "\n",
    "Cette fonction va calculer (par défaut dans la version actuelle de `sklearn`) le score de 3-fold cross validation pour différentes valeurs des paramètres.\n",
    "Visualisez les résultats de la cellule suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_range=10**(np.arange(-3.,4.5,.5))\n",
    "C_range=10**(np.arange(-3.,3.5,.5)) \n",
    "parameters = { 'gamma': gamma_range, 'C': C_range }\n",
    "SVM = svm.SVC(kernel='rbf')\n",
    "gridsearch=model_selection.GridSearchCV(SVM, parameters)\n",
    "gridsearch.fit(X_train,y_train)\n",
    "print(\"Meilleur estimateur trouvé:\")\n",
    "print(gridsearch.best_estimator_)\n",
    "print(\"Meilleurs paramètres:\")\n",
    "print(gridsearch.best_params_)\n",
    "\n",
    "scores = gridsearch.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(scores)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "plt.yticks(np.arange(len(C_range)), C_range)\n",
    "plt.colorbar()\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quel est le score de classification sur la base de test du meilleur classifieur identifié?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votre code ici:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparez au résultat de la classification de la base de test par les algorithmes de classification aux 1,5, 10 plus proches voisins, à la régression logistique, au classifieur naïf gaussien et au perceptron multicouches.\n",
    "\n",
    "_Indication_. Vous utiliserez les paramètres pour le perceptron multicouches:\n",
    "\n",
    "``` hidden_layer_sizes=(7,),max_iter=1000,solver='lbfgs',alpha=0.001,activation='tanh' ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  neighbors, naive_bayes, linear_model, neural_network\n",
    "\n",
    "# votre code ici:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
