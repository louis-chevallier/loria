{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Séminaire IMT Grand-Est\n",
    "\n",
    "# Introduction à l'apprentissage automatique: TP3 - Exercice 1\n",
    "\n",
    "<br>\n",
    "\n",
    "### Reconnaissance de chiffres manuscrits par classification aux plus proches voisins\n",
    "\n",
    "<br>\n",
    "\n",
    "Les méthodes d'apprentissage supervisé de scikit-learn permettent de définir un objet, doté de différents attributs et méthodes, dont `fit` (pour procéder à l'apprentissage), `predict` (pour prédire les classes des éléments d'une base de test), ou `score` pour calculer la proportion d'observations bien classées dans la base de test, lorsqu'on connaît par ailleurs la \"vraie\" classe.\n",
    "\n",
    "Ci-dessous, un exemple d'utilisation, dans un scénario où on suppose disposer d'une base d'apprentissage $(X_{train},y_{train})$, et d'une base de test $X_{test}$ pour laquelle on connaît $y_{test}$.\n",
    "\n",
    "```python\n",
    "# (le code suivant ne peut pas être exécuté \"tel quel\"...\n",
    "\n",
    "# classifieur au plus proche voisin (on peut changer le paramètre n_neighbors):\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)  \n",
    "\n",
    "# on cherchera le p.p.v. dans X_train, la prédiction sera la classe de ce p.p.v., donnée par y_train:\n",
    "knn.fit(X_train,y_train)  # (il n'y a pas d'apprentissage à proprement parler pour les p.p.v.)\n",
    "\n",
    "# on stocke dans y_pred les classes prédites sur un ensemble de test:\n",
    "y_pred = knn.predict(X_test)  \n",
    "\n",
    "# calcul d'un score lorsqu'on connaît les vraies classes des observations de X_test: \n",
    "# (proportion d'observations pour lesquelles y_test==y_pred)\n",
    "score = knn.score(X_test,y_test)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implantez une classification aux $K$ plus proches voisins de la base des chiffres manuscrits extraite de MNIST (cf cellule ci-dessous): vous utiliserez comme base d'apprentissage 50% des données de `digits`, et vous calculerez le score de classification sur les 50% restants, lorsque $K$ varie entre 1 et 15.\n",
    "\n",
    "Quelle valeur de $K$ semble la plus adaptée à ce problème?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, neighbors, linear_model\n",
    "%matplotlib inline \n",
    "\n",
    "# dataset natif sklearn: (lignes à \"décommenter\" pour utiliser ce jeu de données)\n",
    "# size_images=(8,8)\n",
    "# digits = datasets.load_digits()\n",
    "# X_digits = digits.data\n",
    "# y_digits = digits.target\n",
    "\n",
    "# Mnist database: (il faut quelques dizaines de secondes pour charger la base)\n",
    "# les données sont décrites ici: https://www.openml.org/d/554\n",
    "size_images=(28,28)\n",
    "X_digits, y_digits = datasets.fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X_digits=X_digits[:2000,:]\n",
    "y_digits=y_digits[:2000]\n",
    "\n",
    "n_samples = len(X_digits)\n",
    "print(\"nombre total d'observations (apprentissage + test): %d\" % n_samples)\n",
    "\n",
    "n_features = len(X_digits[0])\n",
    "print(\"nombre de caractéristiques par observation: %d\" % n_features)\n",
    "\n",
    "X_train = X_digits[: int(.5*n_samples)]\n",
    "y_train = y_digits[: int(.5*n_samples)]\n",
    "X_test = X_digits[int(.5*n_samples) :] \n",
    "y_test = y_digits[int(.5*n_samples) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votre code ici:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsqu'on fixe la base d'apprentissage et la base de test a priori, on introduit des fluctuations d'échantillonnage: une autre partition de la base de données originale entre apprentissage et test donnerait des scores légèrement différents. D'autre part, la partie de la base initiale réservée au test ne sert jamais pour l'apprentissage, ce qui est dommage.\n",
    "\n",
    "Une manière de dépasser cette limitation est la _validation croisée_ décrite [sur wikipedia](https://fr.wikipedia.org/wiki/Validation_crois%C3%A9e). Constatez que l'on vient d'implémenter la _holdout method_.\n",
    "\n",
    "En vous inspirant de la syntaxe [décrite dans la documentation sklearn](https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics), adaptez le code de la question précédente pour calculer une _5-fold cross validation_ (\"validation croisée à 5 plis\") et une _10-fold cross validation_ (ce sont les deux approches traditionnelles) sur toute la base `digits`. Vous utiliserez la fonction `cross_val_score`. On peut difficilement trop augmenter le nombre de \"plis\" car le temps de calcul grandit.\n",
    "\n",
    "Constatez que le temps de calcul devient handicapant lorsque le nombre de plis augmente: ceci motive les approches _n-fold cross validation_ par rapport à la validation _leave-one-out_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# votre code ici:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante permet d'afficher les 150 premières images d'une base de test, ainsi que la classe déterminée par l'algorithme de classification et la classe véritable, qui est connue dans cet exercice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def affichage_150_images(X_test,y_test,y_pred):\n",
    "    plt.figure(figsize=[15,12])   \n",
    "    for n in range(150):\n",
    "        plt.subplot(10,15,n+1,xticks=[],yticks=[])\n",
    "        plt.imshow(np.reshape(X_test[n,:],size_images),cmap='gray_r',vmin=0,vmax=16)\n",
    "        if y_pred[n]==y_test[n]:\n",
    "            plt.text(0.1,0.1,str(y_pred[n])+' / '+str(y_test[n]),fontsize=6,bbox=dict(facecolor='white', alpha=1))    \n",
    "        else:\n",
    "            plt.text(0.1,0.1,str(y_pred[n])+' / '+str(y_test[n]),fontsize=6,bbox=dict(facecolor='red', alpha=1))    \n",
    "    plt.suptitle('classe predite / classe réelle');\n",
    "\n",
    "# exemple d'utilisation: classification au plus proche voisin et bases train / test de la première question:\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)  # essayez n_neighbors=10\n",
    "%time knn.fit(X_train, y_train)\n",
    "print('KNN score: %f' % knn.score(X_test, y_test))\n",
    "%time y_pred_nn = knn.predict(X_test)\n",
    "affichage_150_images(X_test,y_test,y_pred_nn)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelles sont les informations fournies par `classification_report` et `confusion_matrix` du module `metrics` ? \n",
    "\n",
    "Voir [la documentation](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "    \n",
    "print(metrics.classification_report(y_test,y_pred_nn))\n",
    "# cf http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparez aux résultats obtenus par \n",
    "\n",
    "- la classification naïve bayésienne gaussienne décrite dans la [documentation scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "    \n",
    "-  à la régression logistique, décrite dans la [documentation scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "  \n",
    "Comparez également les temps de calcul.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votre code ici:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
